{"version":3,"file":"analyzers.js","sourceRoot":"","sources":["../../src/analyzers.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;AAYA,oDAAsC;AACtC,6CAAoD;AA+yBpD,YAAY;AAEZ,wBAAwB;AACxB;;;;GAIG;AACH,SAAgB,gBAAgB,CAAC,QAAa;IAC5C,OAAO,OAAO,CAAC,QAAQ,IAAI,QAAQ,CAAC,gBAAgB,CAAC,CAAC;AACxD,CAAC;AAFD,4CAEC;AAED;;GAEG;AACH,MAAa,QAAQ;IACT,KAAK,CAAS;IACd,GAAG,CAAqB;IAElC;;OAEG;IACH,YAAY,EAAsB,EAAE,IAAY;QAC9C,IAAI,CAAC,GAAG,GAAG,EAAE,CAAC;QACd,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAED;;OAEG;IACH,IAAI,QAAQ;QACV,OAAO,IAAI,CAAC,GAAG,CAAC;IAClB,CAAC;IAED;;;;OAIG;IACH,IAAI,gBAAgB;QAClB,OAAO,IAAI,CAAC;IACd,CAAC;IAED;;;;OAIG;IACH,IAAI,IAAI;QACN,OAAO,IAAI,CAAC,KAAK,CAAC;IACpB,CAAC;IAED;;;;;;;;;;OAUG;IACH,KAAK,CAAC,MAAM;QACV,IAAI,CAAC;YACH,MAAM,IAAI,CAAC,GAAG,EAAE,CAAC;YACjB,OAAO,IAAI,CAAC;QACd,CAAC;QAAC,OAAO,GAAQ,EAAE,CAAC;YAClB,IAAI,MAAM,CAAC,aAAa,CAAC,GAAG,CAAC,IAAI,GAAG,CAAC,QAAQ,KAAK,6BAAkB,EAAE,CAAC;gBACrE,OAAO,KAAK,CAAC;YACf,CAAC;YACD,MAAM,GAAG,CAAC;QACZ,CAAC;IACH,CAAC;IAED;;;;;;;;;;OAUG;IACH,GAAG;QACD,OAAO,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC;YACtB,QAAQ,EAAE,kBAAkB,kBAAkB,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE;SAC7D,CAAC,CAAC;IACL,CAAC;IAED;;;;;;;;;;;;;;OAcG;IACH,MAAM,CACJ,OAAgB;QAsChB,OAAO,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC;YACtB,MAAM,EAAE,MAAM;YACd,QAAQ,EAAE,gBAAgB;YAC1B,IAAI,EAAE,EAAE,IAAI,EAAE,IAAI,CAAC,KAAK,EAAE,GAAG,OAAO,EAAE;SACvC,CAAC,CAAC;IACL,CAAC;IAED;;;;;;;;;;;;;OAaG;IACH,IAAI,CACF,QAAiB,KAAK;QAEtB,OAAO,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC;YACtB,MAAM,EAAE,QAAQ;YAChB,QAAQ,EAAE,kBAAkB,kBAAkB,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE;YAC5D,MAAM,EAAE,EAAE,KAAK,EAAE;SAClB,CAAC,CAAC;IACL,CAAC;CACF;AAjKD,4BAiKC;AACD,YAAY","sourcesContent":["/**\n * ```ts\n * import type { Analyzer } from \"arangojs/analyzers\";\n * ```\n *\n * The \"analyzers\" module provides Analyzer related types and interfaces\n * for TypeScript.\n *\n * @packageDocumentation\n */\nimport * as connection from \"./connection.js\";\nimport * as databases from \"./databases.js\";\nimport * as errors from \"./errors.js\";\nimport { ANALYZER_NOT_FOUND } from \"./lib/codes.js\";\n\n//#region Shared types\n/**\n * Name of a feature enabled for an Analyzer.\n */\nexport type AnalyzerFeature = \"frequency\" | \"norm\" | \"position\" | \"offset\";\n\n/**\n * Text case conversion type.\n */\nexport type CaseConversion = \"lower\" | \"upper\" | \"none\";\n\n/**\n * Token type for a Segmentation Analyzer.\n */\nexport type SegmentationTokenType = \"all\" | \"alpha\" | \"graphic\";\n\n/**\n * Token data type for an AQL Analyzer.\n */\nexport type AqlReturnTokenType = \"string\" | \"number\" | \"bool\";\n\n/**\n * GeoJSON type.\n */\nexport type GeoType = \"shape\" | \"centroid\" | \"point\";\n\n/**\n * Storage format of a Geo S2 Analyzer.\n */\nexport type GeoS2Format = \"latLngDouble\" | \"latLngInt\" | \"s2Point\";\n\n/**\n * Type of an Analyzer.\n */\nexport type AnalyzerType = AnalyzerDescription[\"type\"];\n//#endregion\n\n//#region CreateAnalyzerOptions\n/**\n * Analyzer type and its type-specific properties.\n */\nexport type CreateAnalyzerOptions =\n  | CreateIdentityAnalyzerOptions\n  | CreateDelimiterAnalyzerOptions\n  | CreateMultiDelimiterAnalyzerOptions\n  | CreateStemAnalyzerOptions\n  | CreateNormAnalyzerOptions\n  | CreateNgramAnalyzerOptions\n  | CreateTextAnalyzerOptions\n  | CreateSegmentationAnalyzerOptions\n  | CreateAqlAnalyzerOptions\n  | CreatePipelineAnalyzerOptions\n  | CreateStopwordsAnalyzerOptions\n  | CreateCollationAnalyzerOptions\n  | CreateMinHashAnalyzerOptions\n  | CreateClassificationAnalyzerOptions\n  | CreateNearestNeighborsAnalyzerOptions\n  | CreateWildcardAnalyzerOptions\n  | CreateGeoJsonAnalyzerOptions\n  | CreateGeoPointAnalyzerOptions\n  | CreateGeoS2AnalyzerOptions;\n\n/**\n * Shared attributes of all Analyzer creation options.\n */\nexport type CreateAnalyzerOptionsType<\n  Type extends AnalyzerType,\n  Properties = void,\n> = Properties extends void\n  ? {\n      /**\n       * Type of the Analyzer.\n       */\n      type: Type;\n      /**\n       * Features to enable for this Analyzer.\n       */\n      features?: AnalyzerFeature[];\n      /**\n       * This Analyzer does not take additional properties.\n       */\n      properties?: Record<string, never>;\n    }\n  : {\n      /**\n       * Type of the Analyzer.\n       */\n      type: Type;\n      /**\n       * Features to enable for this Analyzer.\n       */\n      features?: AnalyzerFeature[];\n      /**\n       * Additional properties for the Analyzer.\n       */\n      properties: Properties;\n    };\n\n/**\n * Options for creating an Identity Analyzer.\n */\nexport type CreateIdentityAnalyzerOptions =\n  CreateAnalyzerOptionsType<\"identity\">;\n\n/**\n * Options for creating a Delimiter Analyzer.\n */\nexport type CreateDelimiterAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"delimiter\",\n  | string\n  | {\n      /**\n       * This value will be used as delimiter to split text into tokens as\n       * specified in RFC 4180, without starting new records on newlines.\n       */\n      delimiter: string;\n    }\n>;\n\n/**\n * Options for creating a Multi-Delimiter Analyzer.\n */\nexport type CreateMultiDelimiterAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"multi_delimiter\",\n  {\n    /**\n     * This value will be used as delimiter to split text into tokens as\n     * specified in RFC 4180, without starting new records on newlines.\n     */\n    delimiters: string[];\n  }\n>;\n\n/**\n * Options for creating a Stem Analyzer.\n */\nexport type CreateStemAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"stem\",\n  {\n    /**\n     * Text locale.\n     *\n     * Format: `language[_COUNTRY][.encoding][@variant]`\n     */\n    locale: string;\n  }\n>;\n\n/**\n * Options for creating a Norm Analyzer.\n */\nexport type CreateNormAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"norm\",\n  {\n    /**\n     * Text locale.\n     *\n     * Format: `language[_COUNTRY][.encoding][@variant]`\n     */\n    locale: string;\n    /**\n     * Case conversion.\n     *\n     * Default: `\"lower\"`\n     */\n    case?: CaseConversion;\n    /**\n     * Preserve accents in returned words.\n     *\n     * Default: `false`\n     */\n    accent?: boolean;\n  }\n>;\n\n/**\n * Options for creating an Ngram Analyzer.\n */\nexport type CreateNgramAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"ngram\",\n  {\n    /**\n     * Maximum n-gram length.\n     */\n    max: number;\n    /**\n     * Minimum n-gram length.\n     */\n    min: number;\n    /**\n     * Output the original value as well.\n     */\n    preserveOriginal: boolean;\n  }\n>;\n\n/**\n * Options for creating a Text Analyzer.\n */\nexport type CreateTextAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"text\",\n  {\n    /**\n     * Text locale.\n     *\n     * Format: `language[_COUNTRY][.encoding][@variant]`\n     */\n    locale: string;\n    /**\n     * Case conversion.\n     *\n     * Default: `\"lower\"`\n     */\n    case?: CaseConversion;\n    /**\n     * Words to omit from result.\n     *\n     * Defaults to the words loaded from the file at `stopwordsPath`.\n     */\n    stopwords?: string[];\n    /**\n     * Path with a `language` sub-directory containing files with words to omit.\n     *\n     * Defaults to the path specified in the server-side environment variable\n     * `IRESEARCH_TEXT_STOPWORD_PATH` or the current working directory of the\n     * ArangoDB process.\n     */\n    stopwordsPath?: string;\n    /**\n     * Preserve accents in returned words.\n     *\n     * Default: `false`\n     */\n    accent?: boolean;\n    /**\n     * Apply stemming on returned words.\n     *\n     * Default: `true`\n     */\n    stemming?: boolean;\n    /**\n     * If present, then edge n-grams are generated for each token (word).\n     */\n    edgeNgram?: {\n      min?: number;\n      max?: number;\n      preserveOriginal?: boolean;\n    };\n  }\n>;\n\n/**\n * Options for creating a Segmentation Analyzer\n */\nexport type CreateSegmentationAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"segmentation\",\n  {\n    /**\n     * Which tokens should be returned.\n     *\n     * Default: `\"alpha\"`\n     */\n    break?: SegmentationTokenType;\n    /**\n     * What case all returned tokens should be converted to if applicable.\n     *\n     * Default: `\"none\"`\n     */\n    case?: CaseConversion;\n  }\n>;\n\n/**\n * Options for creating an AQL Analyzer\n */\nexport type CreateAqlAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"aql\",\n  {\n    /**\n     * AQL query to be executed.\n     */\n    queryString: string;\n    /**\n     * If set to `true`, the position is set to `0` for all members of the query result array.\n     *\n     * Default: `false`\n     */\n    collapsePositions?: boolean;\n    /**\n     * If set to `false`, `null` values will be discarded from the View index.\n     *\n     * Default: `true`\n     */\n    keepNull?: boolean;\n    /**\n     * Number between `1` and `1000` that determines the batch size for reading\n     * data from the query.\n     *\n     * Default: `1`\n     */\n    batchSize?: number;\n    /**\n     * Memory limit for query execution in bytes.\n     *\n     * Default: `1048576` (1 MiB)\n     */\n    memoryLimit?: number;\n    /**\n     * Data type of the returned tokens.\n     *\n     * Default: `\"string\"`\n     */\n    returnType?: AqlReturnTokenType;\n  }\n>;\n\n/**\n * Options for creating a Pipeline Analyzer\n */\nexport type CreatePipelineAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"pipeline\",\n  {\n    /**\n     * Definitions for Analyzers to chain in this Pipeline Analyzer.\n     */\n    pipeline: Omit<CreateAnalyzerOptions, \"features\">[];\n  }\n>;\n\n/**\n * Options for creating a Stopwords Analyzer\n */\nexport type CreateStopwordsAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"stopwords\",\n  {\n    /**\n     * Array of strings that describe the tokens to be discarded.\n     */\n    stopwords: string[];\n    /**\n     * Whether stopword values should be interpreted as hex-encoded strings.\n     *\n     * Default: `false`\n     */\n    hex?: boolean;\n  }\n>;\n\n/**\n * Options for creating a Collation Analyzer\n */\nexport type CreateCollationAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"collation\",\n  {\n    /**\n     * Text locale.\n     *\n     * Format: `language[_COUNTRY][.encoding][@variant]`\n     */\n    locale: string;\n  }\n>;\n\n/**\n * (Enterprise Edition only.) Options for creating a MinHash Analyzer\n */\nexport type CreateMinHashAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"minhash\",\n  {\n    /**\n     * An Analyzer definition-like object with `type` and `properties` attributes.\n     */\n    analyzer: Omit<CreateAnalyzerOptions, \"features\">;\n    /**\n     * Size of the MinHash signature.\n     */\n    numHashes: number;\n  }\n>;\n\n/**\n * (Enterprise Edition only.) Options for creating a Classification Analyzer\n */\nexport type CreateClassificationAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"classification\",\n  {\n    /**\n     * On-disk path to the trained fastText supervised model.\n     */\n    model_location: string;\n    /**\n     * Number of class labels that will be produced per input.\n     *\n     * Default: `1`\n     */\n    top_k?: number;\n    /**\n     * Probability threshold for which a label will be assigned to an input.\n     *\n     * Default: `0.99`\n     */\n    threshold?: number;\n  }\n>;\n\n/**\n * (Enterprise Edition only.) Options for creating a NearestNeighbors Analyzer.\n */\nexport type CreateNearestNeighborsAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"nearest_neighbors\",\n  {\n    /**\n     * On-disk path to the trained fastText supervised model.\n     */\n    model_location: string;\n    /**\n     * Number of class labels that will be produced per input.\n     *\n     * Default: `1`\n     */\n    top_k?: number;\n  }\n>;\n\n/**\n * Options for creating a Wildcard Analyzer.\n */\nexport type CreateWildcardAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"wildcard\",\n  {\n    /**\n     * N-gram length. Must be a positive integer greater than or equal to 2.\n     */\n    ngramSize: string;\n    /**\n     * An Analyzer definition-like object with `type` and `properties` attributes.\n     */\n    analyzer?: Omit<CreateAnalyzerOptions, \"features\">;\n  }\n>;\n\n/**\n * Options for creating a GeoJSON Analyzer\n */\nexport type CreateGeoJsonAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"geojson\",\n  {\n    /**\n     * If set to `\"centroid\"`, only the centroid of the input geometry will be\n     * computed and indexed.\n     *\n     * If set to `\"point\"` only GeoJSON objects of type Point will be indexed and\n     * all other geometry types will be ignored.\n     *\n     * Default: `\"shape\"`\n     */\n    type?: GeoType;\n    /**\n     * Options for fine-tuning geo queries.\n     *\n     * Default: `{ maxCells: 20, minLevel: 4, maxLevel: 23 }`\n     */\n    options?: {\n      maxCells?: number;\n      minLevel?: number;\n      maxLevel?: number;\n    };\n  }\n>;\n\n/**\n * Options for creating a GeoPoint Analyzer\n */\nexport type CreateGeoPointAnalyzerOptions = CreateAnalyzerOptionsType<\n  \"geopoint\",\n  {\n    /**\n     * Attribute paths of the latitude value relative to the field for which the\n     * Analyzer is defined in the View.\n     */\n    latitude?: string[];\n    /**\n     * Attribute paths of the longitude value relative to the field for which the\n     * Analyzer is defined in the View.\n     */\n    longitude?: string[];\n    /**\n     * Options for fine-tuning geo queries.\n     *\n     * Default: `{ maxCells: 20, minLevel: 4, maxLevel: 23 }`\n     */\n    options?: {\n      minCells?: number;\n      minLevel?: number;\n      maxLevel?: number;\n    };\n  }\n>;\n\n/**\n * (Enterprise Edition only.) Options for creating a Geo S2 Analyzer\n */\nexport type CreateGeoS2AnalyzerOptions = CreateAnalyzerOptionsType<\n  \"geo_s2\",\n  {\n    /**\n     * If set to `\"centroid\"`, only the centroid of the input geometry will be\n     * computed and indexed.\n     *\n     * If set to `\"point\"` only GeoJSON objects of type Point will be indexed and\n     * all other geometry types will be ignored.\n     *\n     * Default: `\"shape\"`\n     */\n    type?: GeoType;\n    /**\n     * Options for fine-tuning geo queries.\n     *\n     * Default: `{ maxCells: 20, minLevel: 4, maxLevel: 23 }`\n     */\n    options?: {\n      maxCells?: number;\n      minLevel?: number;\n      maxLevel?: number;\n    };\n    /**\n     * If set to `\"latLngDouble\"`, each latitude and longitude value is stored\n     * as an 8-byte floating-point value (16 bytes per coordinate pair).\n     *\n     * If set to `\"latLngInt\"`, each latitude and longitude value is stored as\n     * a 4-byte integer value (8 bytes per coordinate pair).\n     *\n     * If set to `\"s2Point\"`, each longitude-latitude pair is stored in the\n     * native format of Google S2 (24 bytes per coordinate pair).\n     *\n     * Default: `\"latLngDouble\"`\n     */\n    format?: GeoS2Format;\n  }\n>;\n//#endregion\n\n//#region AnalyzerDescription\n/**\n * An object describing an Analyzer.\n */\nexport type AnalyzerDescription =\n  | IdentityAnalyzerDescription\n  | DelimiterAnalyzerDescription\n  | MultiDelimiterAnalyzerDescription\n  | StemAnalyzerDescription\n  | NormAnalyzerDescription\n  | NgramAnalyzerDescription\n  | TextAnalyzerDescription\n  | SegmentationAnalyzerDescription\n  | AqlAnalyzerDescription\n  | PipelineAnalyzerDescription\n  | StopwordsAnalyzerDescription\n  | CollationAnalyzerDescription\n  | MinHashAnalyzerDescription\n  | ClassificationAnalyzerDescription\n  | NearestNeighborsAnalyzerDescription\n  | WildcardAnalyzerDescription\n  | GeoJsonAnalyzerDescription\n  | GeoPointAnalyzerDescription\n  | GeoS2AnalyzerDescription;\n\n/**\n * Shared attributes of all Analyzer descriptions.\n */\nexport type AnalyzerDescriptionType<\n  Type extends string,\n  Properties = Record<string, never>,\n> = {\n  /**\n   * A unique name for this Analyzer.\n   */\n  name: string;\n  /**\n   * Type of the Analyzer.\n   */\n  type: Type;\n  /**\n   * Features to enable for this Analyzer.\n   */\n  features?: AnalyzerFeature[];\n  /**\n   * Additional properties for the Analyzer.\n   */\n  properties: Properties;\n};\n\n/**\n * An object describing an Identity Analyzer.\n */\nexport type IdentityAnalyzerDescription = AnalyzerDescriptionType<\"identity\">;\n\n/**\n * An object describing a Delimiter Analyzer.\n */\nexport type DelimiterAnalyzerDescription = AnalyzerDescriptionType<\n  \"delimiter\",\n  { delimiter: string }\n>;\n\n/**\n * An object describing a Multi Delimiter Analyzer.\n */\nexport type MultiDelimiterAnalyzerDescription = AnalyzerDescriptionType<\n  \"multi_delimiter\",\n  { delimiters: string[] }\n>;\n\n/**\n * An object describing a Stem Analyzer.\n */\nexport type StemAnalyzerDescription = AnalyzerDescriptionType<\n  \"stem\",\n  { locale: string }\n>;\n\n/**\n * An object describing a Norm Analyzer.\n */\nexport type NormAnalyzerDescription = AnalyzerDescriptionType<\n  \"norm\",\n  {\n    locale: string;\n    case: CaseConversion;\n    accent: boolean;\n  }\n>;\n\n/**\n * An object describing an Ngram Analyzer.\n */\nexport type NgramAnalyzerDescription = AnalyzerDescriptionType<\n  \"ngram\",\n  {\n    min: number;\n    max: number;\n    preserveOriginal: boolean;\n  }\n>;\n\n/**\n * An object describing a Text Analyzer.\n */\nexport type TextAnalyzerDescription = AnalyzerDescriptionType<\n  \"text\",\n  {\n    locale: string;\n    case: CaseConversion;\n    stopwords: string[];\n    stopwordsPath: string;\n    accent: boolean;\n    stemming: boolean;\n    edgeNgram: {\n      min: number;\n      max: number;\n      preserveOriginal: boolean;\n    };\n  }\n>;\n\n/**\n * An object describing a Segmentation Analyzer\n */\nexport type SegmentationAnalyzerDescription = AnalyzerDescriptionType<\n  \"segmentation\",\n  {\n    break: SegmentationTokenType;\n    case: CaseConversion;\n  }\n>;\n\n/**\n * An object describing an AQL Analyzer\n */\nexport type AqlAnalyzerDescription = AnalyzerDescriptionType<\n  \"aql\",\n  {\n    queryString: string;\n    collapsePositions: boolean;\n    keepNull: boolean;\n    batchSize: number;\n    memoryLimit: number;\n    returnType: AqlReturnTokenType;\n  }\n>;\n\n/**\n * An object describing a Pipeline Analyzer\n */\nexport type PipelineAnalyzerDescription = AnalyzerDescriptionType<\n  \"pipeline\",\n  {\n    pipeline: Omit<AnalyzerDescription, \"name\" | \"features\">[];\n  }\n>;\n\n/**\n * An object describing a Stopwords Analyzer\n */\nexport type StopwordsAnalyzerDescription = AnalyzerDescriptionType<\n  \"stopwords\",\n  {\n    stopwords: string[];\n    hex: boolean;\n  }\n>;\n\n/**\n * An object describing a Collation Analyzer\n */\nexport type CollationAnalyzerDescription = AnalyzerDescriptionType<\n  \"collation\",\n  {\n    locale: string;\n  }\n>;\n\n/**\n * (Enterprise Edition only.) An object describing a MinHash Analyzer\n */\nexport type MinHashAnalyzerDescription = AnalyzerDescriptionType<\n  \"minhash\",\n  {\n    analyzer: Omit<AnalyzerDescription, \"name\" | \"features\">;\n    numHashes: number;\n  }\n>;\n\n/**\n * (Enterprise Edition only.) An object describing a Classification Analyzer\n */\nexport type ClassificationAnalyzerDescription = AnalyzerDescriptionType<\n  \"classification\",\n  {\n    model_location: string;\n    top_k: number;\n    threshold: number;\n  }\n>;\n\n/**\n * (Enterprise Edition only.) An object describing a NearestNeighbors Analyzer\n */\nexport type NearestNeighborsAnalyzerDescription = AnalyzerDescriptionType<\n  \"nearest_neighbors\",\n  {\n    model_location: string;\n    top_k: number;\n  }\n>;\n\n/**\n * An object describing a Wildcard Analyzer\n */\nexport type WildcardAnalyzerDescription = AnalyzerDescriptionType<\n  \"wildcard\",\n  {\n    ngramSize: number;\n    analyzer?: Omit<AnalyzerDescription, \"name\" | \"features\">;\n  }\n>;\n\n/**\n * An object describing a GeoJSON Analyzer\n */\nexport type GeoJsonAnalyzerDescription = AnalyzerDescriptionType<\n  \"geojson\",\n  {\n    type: GeoType;\n    description: {\n      maxCells: number;\n      minLevel: number;\n      maxLevel: number;\n    };\n  }\n>;\n\n/**\n * An object describing a GeoPoint Analyzer\n */\nexport type GeoPointAnalyzerDescription = AnalyzerDescriptionType<\n  \"geopoint\",\n  {\n    latitude: string[];\n    longitude: string[];\n    description: {\n      minCells: number;\n      minLevel: number;\n      maxLevel: number;\n    };\n  }\n>;\n\n/**\n * (Enterprise Edition only.) An object describing a GeoS2 Analyzer\n */\nexport type GeoS2AnalyzerDescription = AnalyzerDescriptionType<\n  \"geo_s2\",\n  {\n    type: GeoType;\n    description: {\n      maxCells: number;\n      minLevel: number;\n      maxLevel: number;\n    };\n    format: GeoS2Format;\n  }\n>;\n//#endregion\n\n//#region Analyzer class\n/**\n * Indicates whether the given value represents an {@link Analyzer}.\n *\n * @param analyzer - A value that might be an Analyzer.\n */\nexport function isArangoAnalyzer(analyzer: any): analyzer is Analyzer {\n  return Boolean(analyzer && analyzer.isArangoAnalyzer);\n}\n\n/**\n * Represents an Analyzer in a {@link databases.Database}.\n */\nexport class Analyzer {\n  protected _name: string;\n  protected _db: databases.Database;\n\n  /**\n   * @internal\n   */\n  constructor(db: databases.Database, name: string) {\n    this._db = db;\n    this._name = name;\n  }\n\n  /**\n   * Database this analyzer belongs to.\n   */\n  get database() {\n    return this._db;\n  }\n\n  /**\n   * @internal\n   *\n   * Indicates that this object represents an ArangoDB Analyzer.\n   */\n  get isArangoAnalyzer(): true {\n    return true;\n  }\n\n  /**\n   * Name of this Analyzer.\n   *\n   * See also {@link databases.Database}.\n   */\n  get name() {\n    return this._name;\n  }\n\n  /**\n   * Checks whether the Analyzer exists.\n   *\n   * @example\n   * ```js\n   * const db = new Database();\n   * const analyzer = db.analyzer(\"some-analyzer\");\n   * const result = await analyzer.exists();\n   * // result indicates whether the Analyzer exists\n   * ```\n   */\n  async exists(): Promise<boolean> {\n    try {\n      await this.get();\n      return true;\n    } catch (err: any) {\n      if (errors.isArangoError(err) && err.errorNum === ANALYZER_NOT_FOUND) {\n        return false;\n      }\n      throw err;\n    }\n  }\n\n  /**\n   * Retrieves the Analyzer definition for the Analyzer.\n   *\n   * @example\n   * ```js\n   * const db = new Database();\n   * const analyzer = db.analyzer(\"some-analyzer\");\n   * const definition = await analyzer.get();\n   * // definition contains the Analyzer definition\n   * ```\n   */\n  get(): Promise<connection.ArangoApiResponse<AnalyzerDescription>> {\n    return this._db.request({\n      pathname: `/_api/analyzer/${encodeURIComponent(this._name)}`,\n    });\n  }\n\n  /**\n   * Creates a new Analyzer with the given `options` and the instance's name.\n   *\n   * See also {@link databases.Database#createAnalyzer}.\n   *\n   * @param options - Options for creating the Analyzer.\n   *\n   * @example\n   * ```js\n   * const db = new Database();\n   * const analyzer = db.analyzer(\"potatoes\");\n   * await analyzer.create({ type: \"identity\" });\n   * // the identity Analyzer \"potatoes\" now exists\n   * ```\n   */\n  create<Options extends CreateAnalyzerOptions>(\n    options: Options\n  ): Promise<\n    Options extends CreateIdentityAnalyzerOptions\n      ? IdentityAnalyzerDescription\n      : Options extends CreateDelimiterAnalyzerOptions\n        ? DelimiterAnalyzerDescription\n        : Options extends CreateStemAnalyzerOptions\n          ? StemAnalyzerDescription\n          : Options extends CreateNormAnalyzerOptions\n            ? NormAnalyzerDescription\n            : Options extends CreateNgramAnalyzerOptions\n              ? NgramAnalyzerDescription\n              : Options extends CreateTextAnalyzerOptions\n                ? TextAnalyzerDescription\n                : Options extends CreateSegmentationAnalyzerOptions\n                  ? SegmentationAnalyzerDescription\n                  : Options extends CreateAqlAnalyzerOptions\n                    ? AqlAnalyzerDescription\n                    : Options extends CreatePipelineAnalyzerOptions\n                      ? PipelineAnalyzerDescription\n                      : Options extends CreateStopwordsAnalyzerOptions\n                        ? StopwordsAnalyzerDescription\n                        : Options extends CreateCollationAnalyzerOptions\n                          ? CollationAnalyzerDescription\n                          : Options extends CreateMinHashAnalyzerOptions\n                            ? MinHashAnalyzerDescription\n                            : Options extends CreateClassificationAnalyzerOptions\n                              ? ClassificationAnalyzerDescription\n                              : Options extends CreateNearestNeighborsAnalyzerOptions\n                                ? NearestNeighborsAnalyzerDescription\n                                : Options extends CreateGeoJsonAnalyzerOptions\n                                  ? GeoJsonAnalyzerDescription\n                                  : Options extends CreateGeoPointAnalyzerOptions\n                                    ? GeoPointAnalyzerDescription\n                                    : Options extends CreateGeoS2AnalyzerOptions\n                                      ? GeoS2AnalyzerDescription\n                                      : AnalyzerDescription\n  > {\n    return this._db.request({\n      method: \"POST\",\n      pathname: \"/_api/analyzer\",\n      body: { name: this._name, ...options },\n    });\n  }\n\n  /**\n   * Deletes the Analyzer from the database.\n   *\n   * @param force - Whether the Analyzer should still be deleted even if it\n   * is currently in use.\n   *\n   * @example\n   * ```js\n   * const db = new Database();\n   * const analyzer = db.analyzer(\"some-analyzer\");\n   * await analyzer.drop();\n   * // the Analyzer \"some-analyzer\" no longer exists\n   * ```\n   */\n  drop(\n    force: boolean = false\n  ): Promise<connection.ArangoApiResponse<{ name: string }>> {\n    return this._db.request({\n      method: \"DELETE\",\n      pathname: `/_api/analyzer/${encodeURIComponent(this._name)}`,\n      search: { force },\n    });\n  }\n}\n//#endregion\n"]}